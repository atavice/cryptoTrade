{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install python-binance library and import crypto data from Binance API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "import config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "api_key = config.api_key\n",
    "api_secret = config.api_secret"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "client = Client(api_key, api_secret)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "# Fetch the data\n",
    "\n",
    "import requests\n",
    "\n",
    "# Function to get top 100 cryptocurrencies from CoinGecko\n",
    "def get_top_200_cryptos():\n",
    "    url = 'https://api.coingecko.com/api/v3/coins/markets'\n",
    "    params = {\n",
    "        'vs_currency': 'usd',\n",
    "        'order': 'market_cap_desc',\n",
    "        'per_page': 200,\n",
    "        'page': 1,\n",
    "        'sparkline': False\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    top_200_cryptos = {coin['name']: coin['symbol'].upper() + 'USDT' for coin in data}\n",
    "    return top_200_cryptos\n",
    "\n",
    "# Function to fetch historical data from Binance\n",
    "def fetch_historical_data(symbol, start_date):\n",
    "    interval = Client.KLINE_INTERVAL_1DAY\n",
    "    klines = client.get_historical_klines(symbol, interval, start_date)\n",
    "    df = pd.DataFrame(klines, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume',\n",
    "        'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for Bitcoin (BTCUSDT)\n",
      "Fetched data for Ethereum (ETHUSDT)\n",
      "Could not fetch data for Tether (USDTUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for BNB (BNBUSDT)\n",
      "Fetched data for Solana (SOLUSDT)\n",
      "Fetched data for USDC (USDCUSDT)\n",
      "Could not fetch data for Lido Staked Ether (STETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for XRP (XRPUSDT)\n",
      "Could not fetch data for Toncoin (TONUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Dogecoin (DOGEUSDT)\n",
      "Fetched data for Cardano (ADAUSDT)\n",
      "Fetched data for Shiba Inu (SHIBUSDT)\n",
      "Fetched data for Avalanche (AVAXUSDT)\n",
      "Fetched data for TRON (TRXUSDT)\n",
      "Fetched data for Wrapped Bitcoin (WBTCUSDT)\n",
      "Fetched data for Chainlink (LINKUSDT)\n",
      "Fetched data for Bitcoin Cash (BCHUSDT)\n",
      "Fetched data for Polkadot (DOTUSDT)\n",
      "Fetched data for NEAR Protocol (NEARUSDT)\n",
      "Fetched data for Polygon (MATICUSDT)\n",
      "Fetched data for Litecoin (LTCUSDT)\n",
      "Fetched data for Internet Computer (ICPUSDT)\n",
      "Fetched data for Uniswap (UNIUSDT)\n",
      "Fetched data for Fetch.ai (FETUSDT)\n",
      "Fetched data for Dai (DAIUSDT)\n",
      "Could not fetch data for LEO Token (LEOUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Ethereum Classic (ETCUSDT)\n",
      "Fetched data for Render (RNDRUSDT)\n",
      "Fetched data for Hedera (HBARUSDT)\n",
      "Fetched data for Pepe (PEPEUSDT)\n",
      "Fetched data for Aptos (APTUSDT)\n",
      "Could not fetch data for Wrapped eETH (WEETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for First Digital USD (FDUSDUSDT)\n",
      "Fetched data for Immutable (IMXUSDT)\n",
      "Could not fetch data for Cronos (CROUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Cosmos Hub (ATOMUSDT)\n",
      "Fetched data for Filecoin (FILUSDT)\n",
      "Could not fetch data for Mantle (MNTUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Stellar (XLMUSDT)\n",
      "Fetched data for Arweave (ARUSDT)\n",
      "Could not fetch data for Renzo Restaked ETH (EZETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for OKB (OKBUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Stacks (STXUSDT)\n",
      "Fetched data for The Graph (GRTUSDT)\n",
      "Could not fetch data for Kaspa (KASUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Optimism (OPUSDT)\n",
      "Fetched data for Arbitrum (ARBUSDT)\n",
      "Fetched data for Bittensor (TAOUSDT)\n",
      "Fetched data for Maker (MKRUSDT)\n",
      "Fetched data for dogwifhat (WIFUSDT)\n",
      "Fetched data for VeChain (VETUSDT)\n",
      "Fetched data for Sui (SUIUSDT)\n",
      "Fetched data for Fantom (FTMUSDT)\n",
      "Fetched data for Monero (XMRUSDT)\n",
      "Could not fetch data for Ethena USDe (USDEUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Injective (INJUSDT)\n",
      "Fetched data for THORChain (RUNEUSDT)\n",
      "Fetched data for Theta Network (THETAUSDT)\n",
      "Fetched data for FLOKI (FLOKIUSDT)\n",
      "Fetched data for Bonk (BONKUSDT)\n",
      "Could not fetch data for Rocket Pool ETH (RETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Celestia (TIAUSDT)\n",
      "Fetched data for Jupiter (JUPUSDT)\n",
      "Could not fetch data for Core (COREUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for GALA (GALAUSDT)\n",
      "Fetched data for Sei (SEIUSDT)\n",
      "Fetched data for Lido DAO (LDOUSDT)\n",
      "Could not fetch data for Bitget Token (BGBUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Mantle Staked Ether (METHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Algorand (ALGOUSDT)\n",
      "Could not fetch data for WhiteBIT Coin (WBTUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Quant (QNTUSDT)\n",
      "Could not fetch data for Ondo (ONDOUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Flow (FLOWUSDT)\n",
      "Could not fetch data for Akash Network (AKTUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Bitcoin SV (BSVUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Aave (AAVEUSDT)\n",
      "Fetched data for Beam (BEAMUSDT)\n",
      "Fetched data for SingularityNET (AGIXUSDT)\n",
      "Fetched data for BitTorrent (BTTUSDT)\n",
      "Could not fetch data for Zebec Protocol (ZBCUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Flare (FLRUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for dYdX (ETHDYDXUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for NEO (NEOUSDT)\n",
      "Fetched data for Ethena (ENAUSDT)\n",
      "Could not fetch data for Cheelee (CHEELUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Axie Infinity (AXSUSDT)\n",
      "Fetched data for MultiversX (EGLDUSDT)\n",
      "Fetched data for Chiliz (CHZUSDT)\n",
      "Fetched data for Worldcoin (WLDUSDT)\n",
      "Could not fetch data for Marinade Staked SOL (MSOLUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Tokenize Xchange (TKXUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Gate (GTUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for eCash (XECUSDT)\n",
      "Fetched data for The Sandbox (SANDUSDT)\n",
      "Fetched data for JasmyCoin (JASMYUSDT)\n",
      "Fetched data for Wormhole (WUSDT)\n",
      "Could not fetch data for Safe (SAFEUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Conflux (CFXUSDT)\n",
      "Could not fetch data for KuCoin (KCSUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for EOS (EOSUSDT)\n",
      "Fetched data for Tezos (XTZUSDT)\n",
      "Could not fetch data for Ronin (RONUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for AIOZ Network (AIOZUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Mina Protocol (MINAUSDT)\n",
      "Fetched data for Synthetix Network (SNXUSDT)\n",
      "Fetched data for ORDI (ORDIUSDT)\n",
      "Fetched data for Starknet (STRKUSDT)\n",
      "Fetched data for Decentraland (MANAUSDT)\n",
      "Could not fetch data for ether.fi Staked ETH (EETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Lido Staked SOL (STSOLUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Ribbon Finance (RBNUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for BOOK OF MEME (BOMEUSDT)\n",
      "Could not fetch data for Kelp DAO Restaked ETH (RSETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for ApeCoin (APEUSDT)\n",
      "Fetched data for Gnosis (GNOUSDT)\n",
      "Fetched data for Helium (HNTUSDT)\n",
      "Fetched data for Pendle (PENDLEUSDT)\n",
      "Fetched data for NEXO (NEXOUSDT)\n",
      "Fetched data for DeXe (DEXEUSDT)\n",
      "Could not fetch data for USDD (USDDUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Kava (KAVAUSDT)\n",
      "Fetched data for Nervos Network (CKBUSDT)\n",
      "Fetched data for IOTA (IOTAUSDT)\n",
      "Fetched data for PancakeSwap (CAKEUSDT)\n",
      "Fetched data for Theta Fuel (TFUELUSDT)\n",
      "Could not fetch data for Echelon Prime (PRIMEUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Axelar (AXLUSDT)\n",
      "Fetched data for Bitcoin Gold (BTGUSDT)\n",
      "Fetched data for Klaytn (KLAYUSDT)\n",
      "Fetched data for Pyth Network (PYTHUSDT)\n",
      "Could not fetch data for Frax (FRAXUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Frax Ether (FRXETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Terra Luna Classic (LUNCUSDT)\n",
      "Could not fetch data for Fasttoken (FTNUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Ocean Protocol (OCEANUSDT)\n",
      "Could not fetch data for SATS (Ordinals) (SATSUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Livepeer (LPTUSDT)\n",
      "Fetched data for Oasis Network (ROSEUSDT)\n",
      "Fetched data for MANTRA (OMUSDT)\n",
      "Fetched data for Blur (BLURUSDT)\n",
      "Could not fetch data for Tether Gold (XAUTUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Swell Ethereum (SWETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Coinbase Wrapped Staked ETH (CBETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Osmosis (OSMOUSDT)\n",
      "Fetched data for WOO (WOOUSDT)\n",
      "Could not fetch data for XDC Network (XDCUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Jito (JTOUSDT)\n",
      "Fetched data for Illuvium (ILVUSDT)\n",
      "Could not fetch data for WEMIX (WEMIXUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Golem (GLMUSDT)\n",
      "Fetched data for Arkham (ARKMUSDT)\n",
      "Could not fetch data for PepeCoin (PEPECOINUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Curve DAO (CRVUSDT)\n",
      "Fetched data for Astar (ASTRUSDT)\n",
      "Fetched data for TrueUSD (TUSDUSDT)\n",
      "Fetched data for 0x Protocol (ZRXUSDT)\n",
      "Fetched data for Raydium (RAYUSDT)\n",
      "Could not fetch data for Staked Frax Ether (SFRXETHUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for SuperVerse (SUPERUSDT)\n",
      "Fetched data for IoTeX (IOTXUSDT)\n",
      "Could not fetch data for APENFT (NFTUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Enjin Coin (ENJUSDT)\n",
      "Could not fetch data for Radix (XRDUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Polymesh (POLYXUSDT)\n",
      "Fetched data for Memecoin (MEMEUSDT)\n",
      "Fetched data for Ethereum Name Service (ENSUSDT)\n",
      "Could not fetch data for Venom (VENOMUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Celo (CELOUSDT)\n",
      "Fetched data for Dymension (DYMUSDT)\n",
      "Fetched data for Trust Wallet (TWTUSDT)\n",
      "Could not fetch data for Aerodrome Finance (AEROUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for 1inch (1INCHUSDT)\n",
      "Could not fetch data for Nosana (NOSUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Reserve Rights (RSRUSDT)\n",
      "Fetched data for Ankr Network (ANKRUSDT)\n",
      "Could not fetch data for MX (MXUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for GMT (GMTUSDT)\n",
      "Fetched data for PAX Gold (PAXGUSDT)\n",
      "Fetched data for AltLayer (ALTUSDT)\n",
      "Fetched data for Zilliqa (ZILUSDT)\n",
      "Fetched data for Ravencoin (RVNUSDT)\n",
      "Fetched data for Siacoin (SCUSDT)\n",
      "Fetched data for Biconomy (BICOUSDT)\n",
      "Could not fetch data for ZetaChain (ZETAUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Galxe (GALUSDT)\n",
      "Fetched data for Terra (LUNAUSDT)\n",
      "Fetched data for Holo (HOTUSDT)\n",
      "Could not fetch data for PayPal USD (PYUSDUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for MAGA (TRUMPUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Could not fetch data for Arcblock (ABTUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Rocket Pool (RPLUSDT)\n",
      "Fetched data for Amp (AMPUSDT)\n",
      "Could not fetch data for Stader ETHx (ETHXUSDT): APIError(code=-1121): Invalid symbol.\n",
      "Fetched data for Manta Network (MANTAUSDT)\n",
      "Fetched data for Qtum (QTUMUSDT)\n",
      "Fetched data for Ether.fi (ETHFIUSDT)\n",
      "Fetched data for Compound (COMPUSDT)\n",
      "Could not fetch data for CorgiAI (CORGIAIUSDT): APIError(code=-1121): Invalid symbol.\n",
      "   timestamp           open           high            low          close  \\\n",
      "0 2019-01-01  3701.23000000  3810.16000000  3642.00000000  3797.14000000   \n",
      "1 2019-01-02  3796.45000000  3882.14000000  3750.45000000  3858.56000000   \n",
      "2 2019-01-03  3857.57000000  3862.74000000  3730.00000000  3766.78000000   \n",
      "3 2019-01-04  3767.20000000  3823.64000000  3703.57000000  3792.01000000   \n",
      "4 2019-01-05  3790.09000000  3840.99000000  3751.00000000  3770.96000000   \n",
      "\n",
      "           volume     close_time  quote_asset_volume  number_of_trades  \\\n",
      "0  23741.68703300  1546387199999   88149249.09230461            154227   \n",
      "1  35156.46336900  1546473599999  133876627.24651060            218538   \n",
      "2  29406.94835900  1546559999999  111657372.69526468            199812   \n",
      "3  29519.55467100  1546646399999  111034550.64066196            192232   \n",
      "4  30490.66775100  1546732799999  115893501.27515878            203673   \n",
      "\n",
      "  taker_buy_base_asset_volume taker_buy_quote_asset_volume ignore  \n",
      "0              12919.15589900            47973435.86685800      0  \n",
      "1              17921.60011400            68277897.66105788      0  \n",
      "2              14793.08326700            56172495.42692984      0  \n",
      "3              15579.30325800            58616203.97789647      0  \n",
      "4              14908.91417500            56667455.38615935      0  \n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "\n",
    "start_date = \"1 January 2019\"\n",
    "top_200_cryptos = get_top_200_cryptos()\n",
    "historical_data = {}\n",
    "\n",
    "for name, symbol in top_200_cryptos.items():\n",
    "    try:\n",
    "        df = fetch_historical_data(symbol, start_date)\n",
    "        historical_data[name] = df\n",
    "        print(f\"Fetched data for {name} ({symbol})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch data for {name} ({symbol}): {e}\")\n",
    "\n",
    "# Print sample data from the first cryptocurrency\n",
    "first_crypto_name = next(iter(historical_data))\n",
    "print(historical_data[first_crypto_name].head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "140"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(historical_data.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-11 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-07-05 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-05-10 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-09-22 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-04-28 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-16 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-11-28 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-18 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-10-14 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-04-26 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-05-11 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-09-17 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-02-28 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-07-23 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-11-27 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-09-29 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-05-05 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-10-19 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-07-26 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-01-10 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-04-29 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-10-15 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-05-14 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-10-25 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-12-17 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-06-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-03-23 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-04-11 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-07-23 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-03-05 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-05-03 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-06-11 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-03-15 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-10-21 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-09-04 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-04-10 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-05-05 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-12-15 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-10-31 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-01-31 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-09-13 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-08-15 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-05-09 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-06-22 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-07-29 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-07-30 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-10-15 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-09-21 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-02-17 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-31 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-04-02 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-11-04 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-09-03 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-09-06 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-07-24 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-09-03 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-14 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-11-22 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-04-03 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-03-29 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-09-24 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-08-10 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-07-09 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-11-07 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-02-20 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-06 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-03-16 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-03-17 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-08-30 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-09-24 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-07-03 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-04-29 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-07-23 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-10-25 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-01-26 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-02-19 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-05-24 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-03-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-04-16 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-06-24 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-02-02 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-09-09 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-19 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-05-28 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-11-19 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-03-08 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-11-24 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-10-28 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-02-08 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-12-07 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-09-22 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-03-17 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-07-18 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-15 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-02-28 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-02-28 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-08-10 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-03-25 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-11-14 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-04-18 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-10-17 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-11-03 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-11-10 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-01-05 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-02-06 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-01-27 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-12-25 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-27 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-07-23 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-03-09 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-28 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-01-25 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-02-19 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-09-25 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-07-06 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-12-09 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2022-05-05 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-08-21 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-02-18 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-01-18 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2021-11-23 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-01-18 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2019-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2024-03-18 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2020-06-25 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "count = 0\n",
    "for df in historical_data.values():\n",
    "    first_cell = df.iloc[0, 0]\n",
    "    print(type(first_cell), first_cell)  # Debugging output\n",
    "    if isinstance(first_cell, datetime):\n",
    "        first_cell = first_cell.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    if first_cell == '2019-01-01 00:00:00':\n",
    "        count += 1\n",
    "count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 0\n",
      "Matching keys: []\n"
     ]
    }
   ],
   "source": [
    "# Count how many crypto we will have with changing start datetime.\n",
    "\n",
    "count = 0\n",
    "matching_keys = []\n",
    "threshold_date = datetime.strptime('2021-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for key, df in historical_data.items():\n",
    "    first_cell = df.iloc[0, 0]\n",
    "    # Convert first cell to datetime if it is not already\n",
    "    if isinstance(first_cell, str):\n",
    "        first_cell = datetime.strptime(first_cell, '%Y-%m-%d %H:%M:%S')\n",
    "    elif isinstance(first_cell, pd.Timestamp):\n",
    "        first_cell = first_cell.to_pydatetime()\n",
    "\n",
    "    if first_cell > threshold_date:\n",
    "        count += 1\n",
    "        matching_keys.append(key)\n",
    "\n",
    "print(\"Count:\", count)\n",
    "print(\"Matching keys:\", matching_keys)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining keys: []\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Set the threshold dates for filtering and trimming\n",
    "threshold_start_date = datetime.strptime('2021-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "threshold_end_date = datetime.strptime('2024-05-15 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Step 1: Filter DataFrames that do not start after the threshold date\n",
    "filtered_historical_data = {}\n",
    "for key, df in historical_data.items():\n",
    "    if not df.empty:\n",
    "        first_cell = df.iloc[0, 0]\n",
    "        if (isinstance(first_cell, str) and datetime.strptime(first_cell, '%Y-%m-%d %H:%M:%S') <= threshold_start_date) or (isinstance(first_cell, pd.Timestamp) and first_cell.to_pydatetime() <= threshold_start_date):\n",
    "            filtered_historical_data[key] = df\n",
    "\n",
    "# Step 2: Trim DataFrames to start from the threshold date if they have older data\n",
    "for key, df in filtered_historical_data.items():\n",
    "    if not df.empty:\n",
    "        # Ensure the first column is a datetime object\n",
    "        if isinstance(df.iloc[0, 0], str):\n",
    "            df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "\n",
    "        # Filter rows to start from the threshold date\n",
    "        filtered_historical_data[key] = df[df.iloc[:, 0] >= threshold_start_date]\n",
    "\n",
    "# Step 3: Remove DataFrames with incorrect start or end dates or length not equal to 1231\n",
    "final_historical_data = {}\n",
    "for key, df in filtered_historical_data.items():\n",
    "    if not df.empty:\n",
    "        start_date = df.iloc[0, 0]\n",
    "        end_date = df.iloc[-1, 0]\n",
    "        if start_date == threshold_start_date and end_date == threshold_end_date and len(df) == 1231:\n",
    "            final_historical_data[key] = df\n",
    "\n",
    "# Update the original dictionary to be the final filtered one\n",
    "historical_data = final_historical_data\n",
    "\n",
    "# Output the remaining keys to confirm\n",
    "print(\"Remaining keys:\", list(historical_data.keys()))\n",
    "print(len(historical_data.keys()))\n",
    "\n",
    "# Optional: Print start and end dates and length of each DataFrame to verify\n",
    "for key, df in historical_data.items():\n",
    "    if not df.empty:\n",
    "        print(f'{key} - start: {df.iloc[0, 0]} to end: {df.iloc[-1, 0]}, length: {len(df)}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "for df in historical_data.values():\n",
    "    print(len(df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "# Optional: Print start and end dates of each DataFrame to verify\n",
    "for key, df in historical_data.items():\n",
    "    print(f'{key} - start: {df.iloc[0, 0]} to end: {df.iloc[-1, 0]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "# Assuming you have a dictionary of DataFrames where each DataFrame represents data for a coin\n",
    "# The dictionary keys represent the coin names\n",
    "\n",
    "# Initialize an empty dictionary to store integral of paths for each coin\n",
    "daily_percent_change_dict = {}\n",
    "\n",
    "# Compute the daily change for each coin\n",
    "for coin, df in historical_data.items():\n",
    "    daily_percent_changes_list = []  # Create a new list for each coin\n",
    "    for i in range(len(df)-1):\n",
    "        # Assuming the 5th column is index 4\n",
    "        daily_change = (float(df.iloc[i+1, 4]) - float(df.iloc[i, 4])) / float(df.iloc[i, 4]) * 100\n",
    "        daily_percent_changes_list.append(round(daily_change, 2))  # Round to 2 decimal places\n",
    "    daily_percent_change_dict[coin] = daily_percent_changes_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Solana'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[178], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdaily_percent_change_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSolana\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Solana'"
     ]
    }
   ],
   "source": [
    "daily_percent_change_dict['Solana']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_percent_change_dict['BNB']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Assuming daily_change_dict is your dictionary with coin names as keys and daily changes list as values\n",
    "\n",
    "# Determine the maximum length of daily change lists\n",
    "max_length = max(len(changes) for changes in daily_percent_change_dict.values())\n",
    "\n",
    "# Pad or truncate daily change lists to the maximum length\n",
    "padded_daily_changes = []\n",
    "for changes in daily_percent_change_dict.values():\n",
    "    padded_changes = changes + [0] * (max_length - len(changes))  # Pad with zeros\n",
    "    # Alternatively, you can truncate longer lists by uncommenting the line below\n",
    "    # padded_changes = changes[:max_length]\n",
    "    padded_daily_changes.append(padded_changes)\n",
    "\n",
    "# Prepare data\n",
    "coins = list(daily_percent_change_dict.keys())\n",
    "X = np.array(padded_daily_changes)  # Convert values to numpy array\n",
    "\n",
    "# Choose the number of clusters (k)\n",
    "k = 5  # You can adjust this number based on your data and requirements\n",
    "\n",
    "# Initialize and fit KMeans model\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Print clustering results\n",
    "for i in range(k):\n",
    "    cluster_coins = [coins[j] for j in range(len(coins)) if cluster_labels[j] == i]\n",
    "    print(f'Cluster {i+1}: {cluster_coins}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
